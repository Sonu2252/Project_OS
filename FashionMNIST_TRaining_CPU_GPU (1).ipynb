{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def preprocess_data(data_loader, device):\n",
        "    processed_data = []\n",
        "    labels = []\n",
        "    for inputs, target in data_loader:\n",
        "        # Perform data preprocessing (placeholder)\n",
        "        inputs, target = inputs.to(device), target.to(device)\n",
        "        processed_data.append(inputs.view(inputs.size(0), -1).cpu().numpy())  # Move to CPU before converting to NumPy\n",
        "        labels.append(target.cpu().numpy())  # Move to CPU before converting to NumPy\n",
        "    return np.concatenate(processed_data), np.concatenate(labels)\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def calculate_metrics(start_time, end_time, num_operations):\n",
        "    duration = end_time - start_time\n",
        "    throughput = num_operations / duration\n",
        "    latency = duration / num_operations\n",
        "    return duration, throughput, latency\n",
        "\n",
        "def main():\n",
        "    # Load Fashion MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Define the neural network, loss function, and optimizer\n",
        "    model = SimpleNet()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    # CPU Preprocessing and Training\n",
        "    start_time_cpu = time.time()\n",
        "\n",
        "    # Train on CPU\n",
        "    cpu_data, cpu_labels = preprocess_data(trainloader, 'cpu')\n",
        "    cpu_data = torch.from_numpy(cpu_data).float()\n",
        "    cpu_labels = torch.from_numpy(cpu_labels).long()\n",
        "    cpu_dataset = torch.utils.data.TensorDataset(cpu_data, cpu_labels)\n",
        "    cpu_train_loader = torch.utils.data.DataLoader(cpu_dataset, batch_size=64, shuffle=True)\n",
        "    train(model, 'cpu', cpu_train_loader, criterion, optimizer)\n",
        "\n",
        "    end_time_cpu = time.time()\n",
        "\n",
        "    # GPU Preprocessing and Training\n",
        "    try:\n",
        "        # Ensure GPU is available\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device('cuda')\n",
        "        else:\n",
        "            raise Exception(\"CUDA not available.\")\n",
        "\n",
        "        # Reload data for GPU preprocessing and training\n",
        "        trainloader_gpu = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "        # Data preprocessing on GPU\n",
        "        gpu_data, gpu_labels = preprocess_data(trainloader_gpu, device)\n",
        "        gpu_data = torch.from_numpy(gpu_data).float().to(device)\n",
        "        gpu_labels = torch.from_numpy(gpu_labels).long().to(device)\n",
        "        gpu_dataset = torch.utils.data.TensorDataset(gpu_data, gpu_labels)\n",
        "        gpu_train_loader = torch.utils.data.DataLoader(gpu_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "        # Train on GPU\n",
        "        model.to(device)\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "        start_time_gpu = time.time()\n",
        "        train(model, device, gpu_train_loader, criterion, optimizer)\n",
        "        end_time_gpu = time.time()\n",
        "\n",
        "        print(\"GPU Benchmark successful.\")\n",
        "    except Exception as e:\n",
        "        print(f\"GPU Benchmark failed: {e}\")\n",
        "        end_time_gpu = start_time_gpu\n",
        "\n",
        "    # Calculate and print metrics\n",
        "    num_operations = len(trainloader.dataset)\n",
        "    cpu_duration, cpu_throughput, cpu_latency = calculate_metrics(start_time_cpu, end_time_cpu, num_operations)\n",
        "    gpu_duration, gpu_throughput, gpu_latency = calculate_metrics(start_time_gpu, end_time_gpu, num_operations)\n",
        "\n",
        "    print(\"\\nPerformance Metrics:\")\n",
        "    print(f\"CPU Duration: {cpu_duration:.6f} seconds\")\n",
        "    print(f\"CPU Throughput: {cpu_throughput:.6f} ops/second\")\n",
        "    print(f\"CPU Latency: {cpu_latency:.12f} seconds/operation\\n\")\n",
        "\n",
        "    if 'start_time_gpu' in locals():\n",
        "        print(f\"GPU Duration: {gpu_duration:.6f} seconds\")\n",
        "        print(f\"GPU Throughput: {gpu_throughput:.6f} ops/second\")\n",
        "        print(f\"GPU Latency: {gpu_latency:.12f} seconds/operation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO5p2Uud3x3A",
        "outputId": "de16d3d0-6b80-46c4-c14d-9c2708037377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Benchmark successful.\n",
            "\n",
            "Performance Metrics:\n",
            "CPU Duration: 14.178895 seconds\n",
            "CPU Throughput: 4231.641608 ops/second\n",
            "CPU Latency: 0.000236314909 seconds/operation\n",
            "\n",
            "GPU Duration: 4.307649 seconds\n",
            "GPU Throughput: 13928.711794 ops/second\n",
            "GPU Latency: 0.000071794148 seconds/operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def preprocess_data(data_loader):\n",
        "    processed_data = []\n",
        "    labels = []\n",
        "    for inputs, target in data_loader:\n",
        "        # Perform data preprocessing (placeholder)\n",
        "        processed_data.append(inputs.view(inputs.size(0), -1).numpy())\n",
        "        labels.append(target.numpy())\n",
        "    return np.concatenate(processed_data), np.concatenate(labels)\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def calculate_metrics(start_time, end_time, num_operations):\n",
        "    duration = end_time - start_time\n",
        "    throughput = num_operations / duration\n",
        "    latency = duration / num_operations\n",
        "    return duration, throughput, latency\n",
        "\n",
        "def main():\n",
        "    # Load Fashion MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Define the neural network, loss function, and optimizer\n",
        "    model = SimpleNet()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    # CPU Preprocessing\n",
        "    start_time_cpu = time.time()\n",
        "\n",
        "    cpu_data, cpu_labels = preprocess_data(trainloader)\n",
        "    cpu_data = torch.from_numpy(cpu_data).float()\n",
        "    cpu_labels = torch.from_numpy(cpu_labels).long()\n",
        "\n",
        "    end_time_cpu = time.time()\n",
        "\n",
        "    # GPU Training\n",
        "    try:\n",
        "        # Ensure GPU is available\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device('cuda')\n",
        "            model.to(device)\n",
        "            optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "        else:\n",
        "            raise Exception(\"CUDA not available.\")\n",
        "\n",
        "        # Reload data for GPU training\n",
        "        trainloader_gpu = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "        gpu_data = cpu_data.to(device)\n",
        "        gpu_labels = cpu_labels.to(device)\n",
        "        gpu_dataset = torch.utils.data.TensorDataset(gpu_data, gpu_labels)\n",
        "        gpu_train_loader = torch.utils.data.DataLoader(gpu_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "        # Train on GPU\n",
        "        start_time_gpu = time.time()\n",
        "        train(model, device, gpu_train_loader, criterion, optimizer)\n",
        "        end_time_gpu = time.time()\n",
        "\n",
        "        print(\"GPU Benchmark successful.\")\n",
        "    except Exception as e:\n",
        "        print(f\"GPU Benchmark failed: {e}\")\n",
        "        end_time_gpu = start_time_gpu\n",
        "\n",
        "    # Calculate and print metrics\n",
        "    num_operations = len(trainloader.dataset)\n",
        "    cpu_duration, cpu_throughput, cpu_latency = calculate_metrics(start_time_cpu, end_time_cpu, num_operations)\n",
        "    gpu_duration, gpu_throughput, gpu_latency = calculate_metrics(start_time_gpu, end_time_gpu, num_operations)\n",
        "\n",
        "    # Combine metrics\n",
        "    total_duration = end_time_gpu - start_time_cpu\n",
        "    total_throughput = num_operations / total_duration\n",
        "    avg_latency = total_duration / num_operations\n",
        "\n",
        "    print(\"\\nCombined Performance Metrics:\")\n",
        "    print(f\"Total Duration: {total_duration:.6f} seconds\")\n",
        "    print(f\"Total Throughput: {total_throughput:.6f} ops/second\")\n",
        "    print(f\"Average Latency: {avg_latency:.12f} seconds/operation\\n\")\n",
        "\n",
        "    print(\"Individual Metrics:\")\n",
        "    print(f\"CPU Duration: {cpu_duration:.6f} seconds\")\n",
        "    print(f\"CPU Throughput: {cpu_throughput:.6f} ops/second\")\n",
        "    print(f\"CPU Latency: {cpu_latency:.12f} seconds/operation\")\n",
        "    print(f\"GPU Duration: {gpu_duration:.6f} seconds\")\n",
        "    print(f\"GPU Throughput: {gpu_throughput:.6f} ops/second\")\n",
        "    print(f\"GPU Latency: {gpu_latency:.12f} seconds/operation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGYljGat5DsU",
        "outputId": "c4c6c51b-2d91-4bb7-87f2-7ffb0e4acfcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Benchmark successful.\n",
            "\n",
            "Combined Performance Metrics:\n",
            "Total Duration: 14.786731 seconds\n",
            "Total Throughput: 4057.691862 ops/second\n",
            "Average Latency: 0.000246445525 seconds/operation\n",
            "\n",
            "Individual Metrics:\n",
            "CPU Duration: 13.566403 seconds\n",
            "CPU Throughput: 4422.690328 ops/second\n",
            "CPU Latency: 0.000226106719 seconds/operation\n",
            "GPU Duration: 1.179706 seconds\n",
            "GPU Throughput: 50860.115112 ops/second\n",
            "GPU Latency: 0.000019661772 seconds/operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We here adjust the architecture according to our specific requirements"
      ],
      "metadata": {
        "id": "AghqBbFXA4UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "# Define a deeper neural network for CPU\n",
        "class DeepNetCPU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNetCPU, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "def preprocess_data_cpu(data_loader):\n",
        "    processed_data = []\n",
        "    labels = []\n",
        "    for inputs, target in data_loader:\n",
        "        # Perform data preprocessing (placeholder)\n",
        "        processed_data.append(inputs.view(inputs.size(0), -1).numpy())\n",
        "        labels.append(target.numpy())\n",
        "    return np.concatenate(processed_data), np.concatenate(labels)\n",
        "\n",
        "def train_cpu(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def calculate_metrics_cpu(start_time, end_time, num_operations):\n",
        "    duration = end_time - start_time\n",
        "    throughput = num_operations / duration\n",
        "    latency = duration / num_operations\n",
        "    return duration, throughput, latency\n",
        "\n",
        "def main_cpu():\n",
        "    # Load Fashion MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Define the deeper neural network for CPU, loss function, and optimizer\n",
        "    model_cpu = DeepNetCPU()\n",
        "    criterion_cpu = nn.CrossEntropyLoss()\n",
        "    optimizer_cpu = optim.SGD(model_cpu.parameters(), lr=0.01)\n",
        "\n",
        "    # CPU Preprocessing\n",
        "    start_time_cpu = time.time()\n",
        "\n",
        "    cpu_data, cpu_labels = preprocess_data_cpu(trainloader)\n",
        "    cpu_data = torch.from_numpy(cpu_data).float()\n",
        "    cpu_labels = torch.from_numpy(cpu_labels).long()\n",
        "\n",
        "    end_time_cpu = time.time()\n",
        "\n",
        "    # Train on CPU\n",
        "    train_cpu(model_cpu, trainloader, criterion_cpu, optimizer_cpu)\n",
        "\n",
        "    # Calculate and print metrics for CPU\n",
        "    num_operations_cpu = len(trainloader.dataset)\n",
        "    cpu_duration, cpu_throughput, cpu_latency = calculate_metrics_cpu(start_time_cpu, end_time_cpu, num_operations_cpu)\n",
        "\n",
        "    print(\"\\nCPU Performance Metrics:\")\n",
        "    print(f\"CPU Duration: {cpu_duration:.6f} seconds\")\n",
        "    print(f\"CPU Throughput: {cpu_throughput:.6f} ops/second\")\n",
        "    print(f\"CPU Latency: {cpu_latency:.12f} seconds/operation\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_cpu()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWyAfUWsA_oz",
        "outputId": "cd5391d4-d79a-4ca8-f9b5-3709f05e3f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CPU Performance Metrics:\n",
            "CPU Duration: 12.614876 seconds\n",
            "CPU Throughput: 4756.289219 ops/second\n",
            "CPU Latency: 0.000210247938 seconds/operation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "# Define a deeper neural network for GPU\n",
        "class DeepNetGPU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNetGPU, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "def preprocess_data_gpu(data_loader, device):\n",
        "    processed_data = []\n",
        "    labels = []\n",
        "    for inputs, target in data_loader:\n",
        "        # Perform data preprocessing (placeholder)\n",
        "        inputs, target = inputs.to(device), target.to(device)\n",
        "        processed_data.append(inputs.view(inputs.size(0), -1).cpu().numpy())  # Move to CPU before converting to NumPy\n",
        "        labels.append(target.cpu().numpy())  # Move to CPU before converting to NumPy\n",
        "    return np.concatenate(processed_data), np.concatenate(labels)\n",
        "\n",
        "def train_gpu(model, device, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def calculate_metrics_gpu(start_time, end_time, num_operations):\n",
        "    duration = end_time - start_time\n",
        "    throughput = num_operations / duration\n",
        "    latency = duration / num_operations\n",
        "    return duration, throughput, latency\n",
        "\n",
        "def main_gpu():\n",
        "    # Load Fashion MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Define the deeper neural network for GPU, loss function, and optimizer\n",
        "    model_gpu = DeepNetGPU()\n",
        "    criterion_gpu = nn.CrossEntropyLoss()\n",
        "    optimizer_gpu = optim.SGD(model_gpu.parameters(), lr=0.01)\n",
        "\n",
        "    # GPU Training\n",
        "    try:\n",
        "        # Ensure GPU is available\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device('cuda')\n",
        "            model_gpu.to(device)\n",
        "            optimizer_gpu = optim.SGD(model_gpu.parameters(), lr=0.01)\n",
        "        else:\n",
        "            raise Exception(\"CUDA not available.\")\n",
        "\n",
        "        # Reload data for GPU training\n",
        "        trainloader_gpu = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "        gpu_data, gpu_labels = preprocess_data_gpu(trainloader_gpu, device)\n",
        "        gpu_data = torch.from_numpy(gpu_data).float().to(device)\n",
        "        gpu_labels = torch.from_numpy(gpu_labels).long().to(device)\n",
        "        gpu_dataset = torch.utils.data.TensorDataset(gpu_data, gpu_labels)\n",
        "        gpu_train_loader = torch.utils.data.DataLoader(gpu_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "        # Train on GPU\n",
        "        start_time_gpu = time.time()\n",
        "        train_gpu(model_gpu, device, gpu_train_loader, criterion_gpu, optimizer_gpu)\n",
        "        end_time_gpu = time.time()\n",
        "\n",
        "        print(\"GPU Benchmark successful.\")\n",
        "    except Exception as e:\n",
        "        print(f\"GPU Benchmark failed: {e}\")\n",
        "        end_time_gpu = start_time_gpu\n",
        "\n",
        "    # Calculate and print metrics for GPU\n",
        "    num_operations_gpu = len(trainloader.dataset)\n",
        "    gpu_duration, gpu_throughput, gpu_latency = calculate_metrics_gpu(start_time_gpu, end_time_gpu, num_operations_gpu)\n",
        "\n",
        "    print(\"\\nGPU Performance Metrics:\")\n",
        "    print(f\"GPU Duration: {gpu_duration:.6f} seconds\")\n",
        "    print(f\"GPU Throughput: {gpu_throughput:.6f} ops/second\")\n",
        "    print(f\"GPU Latency: {gpu_latency:.12f} seconds/operation\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_gpu()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QdcDzQwAHrW",
        "outputId": "9707dec9-4eff-4cd3-a79d-ba91a5120c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Benchmark successful.\n",
            "\n",
            "GPU Performance Metrics:\n",
            "GPU Duration: 19.909619 seconds\n",
            "GPU Throughput: 3013.618716 ops/second\n",
            "GPU Latency: 0.000331826981 seconds/operation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "# Define a deeper neural network\n",
        "class DeepNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "def preprocess_data(data_loader):\n",
        "    processed_data = []\n",
        "    labels = []\n",
        "    for inputs, target in data_loader:\n",
        "        # Perform data preprocessing (placeholder)\n",
        "        processed_data.append(inputs.view(inputs.size(0), -1).numpy())\n",
        "        labels.append(target.numpy())\n",
        "    return np.concatenate(processed_data), np.concatenate(labels)\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def calculate_metrics(start_time, end_time, num_operations):\n",
        "    duration = end_time - start_time\n",
        "    throughput = num_operations / duration\n",
        "    latency = duration / num_operations\n",
        "    return duration, throughput, latency\n",
        "\n",
        "def main():\n",
        "    # Load Fashion MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Define the deeper neural network, loss function, and optimizer\n",
        "    model = DeepNet()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    # CPU Preprocessing\n",
        "    start_time_cpu = time.time()\n",
        "\n",
        "    cpu_data, cpu_labels = preprocess_data(trainloader)\n",
        "    cpu_data = torch.from_numpy(cpu_data).float()\n",
        "    cpu_labels = torch.from_numpy(cpu_labels).long()\n",
        "\n",
        "    end_time_cpu = time.time()\n",
        "\n",
        "    # GPU Training\n",
        "    try:\n",
        "        # Ensure GPU is available\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device('cuda')\n",
        "            model.to(device)\n",
        "            optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "        else:\n",
        "            raise Exception(\"CUDA not available.\")\n",
        "\n",
        "        # Reload data for GPU training\n",
        "        trainloader_gpu = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "        gpu_data = cpu_data.to(device)\n",
        "        gpu_labels = cpu_labels.to(device)\n",
        "        gpu_dataset = torch.utils.data.TensorDataset(gpu_data, gpu_labels)\n",
        "        gpu_train_loader = torch.utils.data.DataLoader(gpu_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "        # Train on GPU\n",
        "        start_time_gpu = time.time()\n",
        "        train(model, device, gpu_train_loader, criterion, optimizer)\n",
        "        end_time_gpu = time.time()\n",
        "\n",
        "        print(\"GPU Benchmark successful.\")\n",
        "    except Exception as e:\n",
        "        print(f\"GPU Benchmark failed: {e}\")\n",
        "        end_time_gpu = start_time_gpu\n",
        "\n",
        "    # Calculate and print metrics\n",
        "    num_operations = len(trainloader.dataset)\n",
        "    cpu_duration, cpu_throughput, cpu_latency = calculate_metrics(start_time_cpu, end_time_cpu, num_operations)\n",
        "    gpu_duration, gpu_throughput, gpu_latency = calculate_metrics(start_time_gpu, end_time_gpu, num_operations)\n",
        "\n",
        "    # Combine metrics\n",
        "    total_duration = end_time_gpu - start_time_cpu\n",
        "    total_throughput = num_operations / total_duration\n",
        "    avg_latency = total_duration / num_operations\n",
        "\n",
        "    print(\"\\nCombined Performance Metrics:\")\n",
        "    print(f\"Total Duration: {total_duration:.6f} seconds\")\n",
        "    print(f\"Total Throughput: {total_throughput:.6f} ops/second\")\n",
        "    print(f\"Average Latency: {avg_latency:.12f} seconds/operation\\n\")\n",
        "\n",
        "    print(\"Individual Metrics:\")\n",
        "    print(f\"CPU Duration: {cpu_duration:.6f} seconds\")\n",
        "    print(f\"CPU Throughput: {cpu_throughput:.6f} ops/second\")\n",
        "    print(f\"CPU Latency: {cpu_latency:.12f} seconds/operation\")\n",
        "    print(f\"GPU Duration: {gpu_duration:.6f} seconds\")\n",
        "    print(f\"GPU Throughput: {gpu_throughput:.6f} ops/second\")\n",
        "    print(f\"GPU Latency: {gpu_latency:.12f} seconds/operation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwXXV1_mBDsB",
        "outputId": "5d16cdf8-363b-4c7d-b3ff-33e7ed7072f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Benchmark successful.\n",
            "\n",
            "Combined Performance Metrics:\n",
            "Total Duration: 14.911492 seconds\n",
            "Total Throughput: 4023.742196 ops/second\n",
            "Average Latency: 0.000248524868 seconds/operation\n",
            "\n",
            "Individual Metrics:\n",
            "CPU Duration: 13.083973 seconds\n",
            "CPU Throughput: 4585.762912 ops/second\n",
            "CPU Latency: 0.000218066223 seconds/operation\n",
            "GPU Duration: 1.785562 seconds\n",
            "GPU Throughput: 33602.864929 ops/second\n",
            "GPU Latency: 0.000029759367 seconds/operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lets do it for 10 epochs for both CPU and GPU"
      ],
      "metadata": {
        "id": "ZqNE0qcV05AP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modifies the preprocessing on CPU and training on GPU"
      ],
      "metadata": {
        "id": "JrNtCQJq175s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We get the real difference from here in this code"
      ],
      "metadata": {
        "id": "S7s21gNQipnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "# Define a deeper neural network for GPU\n",
        "class DeepNetGPU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNetGPU, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "def preprocess_data_gpu(data_loader, device):\n",
        "    processed_data = []\n",
        "    labels = []\n",
        "    for inputs, target in data_loader:\n",
        "        # Perform data preprocessing (placeholder)\n",
        "        inputs, target = inputs.to(device), target.to(device)\n",
        "        processed_data.append(inputs.view(inputs.size(0), -1).cpu().numpy())\n",
        "        labels.append(target.cpu().numpy())\n",
        "    return np.concatenate(processed_data), np.concatenate(labels)\n",
        "\n",
        "def train_gpu(model, device, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def calculate_metrics_gpu(start_preprocessing, end_preprocessing, start_training, end_training, num_operations):\n",
        "    preprocessing_duration = end_preprocessing - start_preprocessing\n",
        "    training_duration = end_training - start_training\n",
        "    total_duration = preprocessing_duration + training_duration\n",
        "    throughput = num_operations / total_duration\n",
        "    preprocessing_latency = preprocessing_duration / num_operations\n",
        "    training_latency = training_duration / num_operations\n",
        "    total_latency = total_duration / num_operations\n",
        "\n",
        "    return total_duration, throughput, preprocessing_latency, training_latency, total_latency\n",
        "\n",
        "def main_gpu():\n",
        "    # Load Fashion MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Define the deeper neural network for GPU, loss function, and optimizer\n",
        "    model_gpu = DeepNetGPU()\n",
        "    criterion_gpu = nn.CrossEntropyLoss()\n",
        "    optimizer_gpu = optim.SGD(model_gpu.parameters(), lr=0.01)\n",
        "\n",
        "    # GPU Training\n",
        "    try:\n",
        "        # Ensure GPU is available\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device('cuda')\n",
        "            model_gpu.to(device)\n",
        "            optimizer_gpu = optim.SGD(model_gpu.parameters(), lr=0.01)\n",
        "        else:\n",
        "            raise Exception(\"CUDA not available.\")\n",
        "\n",
        "        # Reload data for GPU training\n",
        "        trainloader_gpu = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "        # GPU Preprocessing\n",
        "        start_time_preprocessing_gpu = time.time()\n",
        "        gpu_data, gpu_labels = preprocess_data_gpu(trainloader_gpu, device)\n",
        "        gpu_data = torch.from_numpy(gpu_data).float().to(device)\n",
        "        gpu_labels = torch.from_numpy(gpu_labels).long().to(device)\n",
        "        gpu_dataset = torch.utils.data.TensorDataset(gpu_data, gpu_labels)\n",
        "        gpu_train_loader = torch.utils.data.DataLoader(gpu_dataset, batch_size=64, shuffle=True)\n",
        "        end_time_preprocessing_gpu = time.time()\n",
        "\n",
        "        # Train on GPU\n",
        "        start_time_training_gpu = time.time()\n",
        "        train_gpu(model_gpu, device, gpu_train_loader, criterion_gpu, optimizer_gpu, epochs=10)\n",
        "        end_time_training_gpu = time.time()\n",
        "\n",
        "        print(\"GPU Benchmark successful.\")\n",
        "    except Exception as e:\n",
        "        print(f\"GPU Benchmark failed: {e}\")\n",
        "        end_time_training_gpu = start_time_training_gpu\n",
        "        end_time_preprocessing_gpu = start_time_preprocessing_gpu\n",
        "\n",
        "    # Calculate and print metrics for GPU\n",
        "    num_operations_gpu = len(trainloader.dataset)\n",
        "    gpu_duration, gpu_throughput, gpu_preprocessing_latency, gpu_training_latency, gpu_total_latency = calculate_metrics_gpu(\n",
        "        start_time_preprocessing_gpu, end_time_preprocessing_gpu, start_time_training_gpu, end_time_training_gpu,\n",
        "        num_operations_gpu\n",
        "    )\n",
        "\n",
        "    print(\"\\nGPU Performance Metrics:\")\n",
        "    print(f\"GPU Total Duration: {gpu_duration:.6f} seconds\")\n",
        "    print(f\"GPU Throughput: {gpu_throughput:.6f} ops/second\")\n",
        "    print(f\"GPU Preprocessing Latency: {gpu_preprocessing_latency:.12f} seconds/operation\")\n",
        "    print(f\"GPU Training Latency: {gpu_training_latency:.12f} seconds/operation\")\n",
        "    print(f\"GPU Total Latency: {gpu_total_latency:.12f} seconds/operation\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_gpu()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU75vkqRjsbm",
        "outputId": "6c8c5e85-3d2f-4f20-f673-3b32aefc840f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Benchmark successful.\n",
            "\n",
            "GPU Performance Metrics:\n",
            "GPU Total Duration: 34.816493 seconds\n",
            "GPU Throughput: 1723.321208 ops/second\n",
            "GPU Preprocessing Latency: 0.000228734322 seconds/operation\n",
            "GPU Training Latency: 0.000351540554 seconds/operation\n",
            "GPU Total Latency: 0.000580274876 seconds/operation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Take this\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "# Define a deeper neural network for CPU\n",
        "class DeepNetCPU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNetCPU, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "def preprocess_data_cpu(data_loader):\n",
        "    processed_data = []\n",
        "    labels = []\n",
        "    for inputs, target in data_loader:\n",
        "        # Perform data preprocessing (placeholder)\n",
        "        processed_data.append(inputs.view(inputs.size(0), -1).numpy())\n",
        "        labels.append(target.numpy())\n",
        "    return np.concatenate(processed_data), np.concatenate(labels)\n",
        "\n",
        "def train_cpu(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def calculate_metrics_cpu(start_preprocessing, end_preprocessing, start_training, end_training, num_operations):\n",
        "    preprocessing_duration = end_preprocessing - start_preprocessing\n",
        "    training_duration = end_training - start_training\n",
        "    total_duration = preprocessing_duration + training_duration\n",
        "    throughput = num_operations / total_duration\n",
        "    preprocessing_latency = preprocessing_duration / num_operations\n",
        "    training_latency = training_duration / num_operations\n",
        "\n",
        "    return total_duration, throughput, preprocessing_latency, training_latency\n",
        "\n",
        "def main_cpu():\n",
        "    # Load Fashion MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Define the deeper neural network for CPU, loss function, and optimizer\n",
        "    model_cpu = DeepNetCPU()\n",
        "    criterion_cpu = nn.CrossEntropyLoss()\n",
        "    optimizer_cpu = optim.SGD(model_cpu.parameters(), lr=0.01)\n",
        "\n",
        "    # CPU Preprocessing\n",
        "    start_time_preprocessing = time.time()\n",
        "\n",
        "    cpu_data, cpu_labels = preprocess_data_cpu(trainloader)\n",
        "    cpu_data = torch.from_numpy(cpu_data).float()\n",
        "    cpu_labels = torch.from_numpy(cpu_labels).long()\n",
        "\n",
        "    end_time_preprocessing = time.time()\n",
        "\n",
        "    # Train on CPU\n",
        "    start_time_training = time.time()\n",
        "    train_cpu(model_cpu, trainloader, criterion_cpu, optimizer_cpu)\n",
        "    end_time_training = time.time()\n",
        "\n",
        "    # Calculate and print metrics for CPU\n",
        "    num_operations_cpu = len(trainloader.dataset)\n",
        "    cpu_duration, cpu_throughput, cpu_preprocessing_latency, cpu_training_latency = calculate_metrics_cpu(\n",
        "        start_time_preprocessing, end_time_preprocessing, start_time_training, end_time_training, num_operations_cpu\n",
        "    )\n",
        "\n",
        "    print(\"\\nCPU Performance Metrics:\")\n",
        "    print(f\"CPU Total Duration: {cpu_duration:.6f} seconds\")\n",
        "    print(f\"CPU Throughput: {cpu_throughput:.6f} ops/second\")\n",
        "    print(f\"CPU Preprocessing Latency: {cpu_preprocessing_latency:.12f} seconds/operation\")\n",
        "    print(f\"CPU Training Latency: {cpu_training_latency:.12f} seconds/operation\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_cpu()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBFx-ezpfMY_",
        "outputId": "b3460eeb-74be-412a-c186-0f26b3ccb8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CPU Performance Metrics:\n",
            "CPU Total Duration: 181.355536 seconds\n",
            "CPU Throughput: 330.841845 ops/second\n",
            "CPU Preprocessing Latency: 0.000209672403 seconds/operation\n",
            "CPU Training Latency: 0.002812919859 seconds/operation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "# Define a deeper neural network for GPU\n",
        "class DeepNetGPU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNetGPU, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "def preprocess_data_cpu(data_loader):\n",
        "    processed_data = []\n",
        "    labels = []\n",
        "    for inputs, target in data_loader:\n",
        "        # Perform data preprocessing on CPU (placeholder)\n",
        "        processed_data.append(inputs.view(inputs.size(0), -1).numpy())\n",
        "        labels.append(target.numpy())\n",
        "    return np.concatenate(processed_data), np.concatenate(labels)\n",
        "\n",
        "def train_gpu(model, device, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def calculate_metrics(start_cpu, end_cpu, start_gpu, end_gpu, num_operations):\n",
        "    cpu_duration = end_cpu - start_cpu\n",
        "    gpu_duration = end_gpu - start_gpu\n",
        "    overall_duration = end_gpu - start_cpu\n",
        "\n",
        "    cpu_throughput = num_operations / cpu_duration\n",
        "    gpu_throughput = num_operations / gpu_duration\n",
        "    overall_throughput = num_operations / overall_duration\n",
        "\n",
        "    cpu_latency = cpu_duration / num_operations\n",
        "    gpu_latency = gpu_duration / num_operations\n",
        "    overall_latency = overall_duration / num_operations\n",
        "\n",
        "    return cpu_duration, cpu_throughput, cpu_latency, gpu_duration, gpu_throughput, gpu_latency, overall_duration, overall_throughput, overall_latency\n",
        "\n",
        "def main_cpu_gpu():\n",
        "    # Load Fashion MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Define the deeper neural network for GPU, loss function, and optimizer\n",
        "    model_gpu = DeepNetGPU()\n",
        "    criterion_gpu = nn.CrossEntropyLoss()\n",
        "    optimizer_gpu = optim.SGD(model_gpu.parameters(), lr=0.01)\n",
        "\n",
        "    # CPU Preprocessing\n",
        "    start_time_cpu = time.time()\n",
        "\n",
        "    cpu_data, cpu_labels = preprocess_data_cpu(trainloader)\n",
        "    cpu_data = torch.from_numpy(cpu_data).float()\n",
        "    cpu_labels = torch.from_numpy(cpu_labels).long()\n",
        "\n",
        "    end_time_cpu = time.time()\n",
        "\n",
        "    # GPU Training\n",
        "    try:\n",
        "        # Ensure GPU is available\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device('cuda')\n",
        "            model_gpu.to(device)\n",
        "            optimizer_gpu = optim.SGD(model_gpu.parameters(), lr=0.01)\n",
        "        else:\n",
        "            raise Exception(\"CUDA not available.\")\n",
        "\n",
        "        # Reload data for GPU training\n",
        "        trainloader_gpu = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "        gpu_data, gpu_labels = preprocess_data_cpu(trainloader_gpu)  # Preprocess on CPU for GPU training\n",
        "        gpu_data = torch.from_numpy(gpu_data).float().to(device)\n",
        "        gpu_labels = torch.from_numpy(gpu_labels).long().to(device)\n",
        "        gpu_dataset = torch.utils.data.TensorDataset(gpu_data, gpu_labels)\n",
        "        gpu_train_loader = torch.utils.data.DataLoader(gpu_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "        # Train on GPU\n",
        "        start_time_gpu = time.time()\n",
        "        train_gpu(model_gpu, device, gpu_train_loader, criterion_gpu, optimizer_gpu)\n",
        "        end_time_gpu = time.time()\n",
        "\n",
        "        print(\"GPU Benchmark successful.\")\n",
        "    except Exception as e:\n",
        "        print(f\"GPU Benchmark failed: {e}\")\n",
        "        end_time_gpu = start_time_gpu\n",
        "\n",
        "    # Calculate and print metrics for CPU and GPU\n",
        "    num_operations_cpu = len(trainloader.dataset)\n",
        "    num_operations_gpu = len(trainloader_gpu.dataset)\n",
        "    cpu_duration, cpu_throughput, cpu_latency, gpu_duration, gpu_throughput, gpu_latency, overall_duration, overall_throughput, overall_latency = calculate_metrics(\n",
        "        start_time_cpu, end_time_cpu, start_time_gpu, end_time_gpu, num_operations_gpu\n",
        "    )\n",
        "\n",
        "    print(\"\\nCPU Performance Metrics:\")\n",
        "    print(f\"CPU Duration: {cpu_duration:.6f} seconds\")\n",
        "    print(f\"CPU Throughput: {cpu_throughput:.6f} ops/second\")\n",
        "    print(f\"CPU Latency: {cpu_latency:.12f} seconds/operation\\n\")\n",
        "\n",
        "    print(\"\\nGPU Performance Metrics:\")\n",
        "    print(f\"GPU Duration: {gpu_duration:.6f} seconds\")\n",
        "    print(f\"GPU Throughput: {gpu_throughput:.6f} ops/second\")\n",
        "    print(f\"GPU Latency: {gpu_latency:.12f} seconds/operation\\n\")\n",
        "\n",
        "    print(\"\\nOverall Performance Metrics:\")\n",
        "    print(f\"Overall Duration: {overall_duration:.6f} seconds\")\n",
        "    print(f\"Overall Throughput: {overall_throughput:.6f} ops/second\")\n",
        "    print(f\"Overall Latency: {overall_latency:.12f} seconds/operation\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_cpu_gpu()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH6hu4MWfwII",
        "outputId": "928b84ce-b220-4f3e-e704-86ec57e1a873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Benchmark successful.\n",
            "\n",
            "CPU Performance Metrics:\n",
            "CPU Duration: 14.222668 seconds\n",
            "CPU Throughput: 4218.617651 ops/second\n",
            "CPU Latency: 0.000237044473 seconds/operation\n",
            "\n",
            "\n",
            "GPU Performance Metrics:\n",
            "GPU Duration: 22.914371 seconds\n",
            "GPU Throughput: 2618.444064 ops/second\n",
            "GPU Latency: 0.000381906192 seconds/operation\n",
            "\n",
            "\n",
            "Overall Performance Metrics:\n",
            "Overall Duration: 50.143075 seconds\n",
            "Overall Throughput: 1196.575998 ops/second\n",
            "Overall Latency: 0.000835717916 seconds/operation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tcv_lRnkjWr6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}