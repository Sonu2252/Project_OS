{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7fptf1HZgJW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**On CPU**"
      ],
      "metadata": {
        "id": "nHXvJuU7gMzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**On GPU**"
      ],
      "metadata": {
        "id": "_7F2lTfigT7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "def io_intensive_task(file_path):\n",
        "    # Read a large file and perform some simple computation\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = file.read()\n",
        "\n",
        "    # Process the data (in this case, just calculate the length)\n",
        "    result = len(data)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Create a large dummy file\n",
        "file_path = 'large_file.txt'\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write('Hello' * 10**9)  # Write 100 MB of 'A' characters\n",
        "\n",
        "# Measure CPU duration\n",
        "start_time_cpu = time.time()\n",
        "\n",
        "result_cpu = io_intensive_task(file_path)\n",
        "\n",
        "end_time_cpu = time.time()\n",
        "\n",
        "# Calculate metrics\n",
        "duration_cpu = end_time_cpu - start_time_cpu\n",
        "num_operations_cpu = 1  # One I/O operation\n",
        "throughput_cpu = num_operations_cpu / duration_cpu\n",
        "latency_cpu = duration_cpu / num_operations_cpu\n",
        "\n",
        "# Print results\n",
        "print(f\"Result (CPU): {result_cpu}\")\n",
        "print(\"\\nPerformance Metrics (CPU):\")\n",
        "print(f\"CPU Duration: {duration_cpu:.6f} seconds\")\n",
        "print(f\"Number of Operations: {num_operations_cpu}\")\n",
        "print(f\"Throughput: {throughput_cpu:.6f} ops/second\")\n",
        "print(f\"Latency: {latency_cpu:.12f} seconds/operation\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r00MMLm5gQG5",
        "outputId": "0b2e0f1b-2337-4407-9acd-1deca7604646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result (CPU): 5000000000\n",
            "\n",
            "Performance Metrics (CPU):\n",
            "CPU Duration: 26.080542 seconds\n",
            "Number of Operations: 1\n",
            "Throughput: 0.038343 ops/second\n",
            "Latency: 26.080542325974 seconds/operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "def io_intensive_task(file_path):\n",
        "    # Read a large file and perform some simple computation\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = file.read()\n",
        "\n",
        "    # Process the data (in this case, just calculate the length)\n",
        "    result = len(data)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Create a large dummy file\n",
        "file_path = 'large_file.txt'\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write('Hello' * 10**9)  # Write 100 MB of 'A' characters\n",
        "\n",
        "# Measure CPU duration\n",
        "start_time_cpu = time.time()\n",
        "\n",
        "result_cpu = io_intensive_task(file_path)\n",
        "\n",
        "end_time_cpu = time.time()\n",
        "\n",
        "# Calculate metrics\n",
        "duration_cpu = end_time_cpu - start_time_cpu\n",
        "num_operations_cpu = 1  # One I/O operation\n",
        "throughput_cpu = num_operations_cpu / duration_cpu\n",
        "latency_cpu = duration_cpu / num_operations_cpu\n",
        "\n",
        "# Print results\n",
        "print(f\"Result (GPU): {result_cpu}\")\n",
        "print(\"\\nPerformance Metrics (GPU):\")\n",
        "print(f\"GPU Duration: {duration_cpu:.6f} seconds\")\n",
        "print(f\"Number of Operations: {num_operations_cpu}\")\n",
        "print(f\"Throughput: {throughput_cpu:.6f} ops/second\")\n",
        "print(f\"Latency: {latency_cpu:.12f} seconds/operation\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaahkLPngWVV",
        "outputId": "874da6f0-f0f9-4cec-b3c8-dd6bb1f662c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result (GPU): 5000000000\n",
            "\n",
            "Performance Metrics (GPU):\n",
            "GPU Duration: 27.826101 seconds\n",
            "Number of Operations: 1\n",
            "Throughput: 0.035937 ops/second\n",
            "Latency: 27.826100587845 seconds/operation\n"
          ]
        }
      ]
    }
  ]
}